---
alwaysApply: true
description: Meta-Framework Generator — Produces project-specific rulebooks (personas, validators, protocols, validation) from any brief or repo
codexAlignmentVersion: 1.0.0
codexAlignmentHash: 2024-06-05-a
---

# Meta-Framework Generator (Rulebook-of-Rulebooks)

## [STRICT] Purpose
Generate a complete, project-specific execution rulebook (personas, validators, protocols, validation flows, evidence map) from any input (brief, repo, constraints). This meta-framework does NOT execute work; it creates the system that will.

## [STRICT] Core Outcomes
- Phase personas + validator personas with system instructions and I/O contracts
- Phase protocols with [STRICT]/[GUIDELINE] directives, success criteria, ✅/❌ examples
- Evidence scaffolding and validation session scripts
- JSON schemas for phase transitions and evidence manifests

## [STRICT] Inputs
- Required:
  - `brief.md` or `AGENTS.md` directives, or repository scan (if present)
- Optional:
  - Compliance targets: SOC2/GDPR/PCI/Accessibility
  - Tech constraints: languages, frameworks, IaC, deploy targets
  - Delivery constraints: deadlines, SLAs, environments, budgets

## [STRICT] Outputs (Generated)
- `/.cursor/rules/_generated/<project-id>/personas.mdc`
- `/.cursor/rules/_generated/<project-id>/protocols.mdc`
- `/docs/plans/<project-id>/phase-map.md`
- `/var/schemas/<project-id>/phase-contracts/*.schema.json`
- `/var/validation/<project-id>/README.md` (sessions: builder/auditor/challenger)

## [STRICT] 4 Pillars Enforcement
- Structure/Discoverability: single entrypoint `master-rule.mdc` linking all artifacts
- Persona/Intent: each phase starts with Persona + System Instruction + Core Principle
- Precision with Prefixes: every directive uses [STRICT]/[GUIDELINE]
- Examples: each phase includes ✅/❌ with why-pass/why-fail

---

## [STRICT] Meta-Generator Protocol (This file governs generation)

### [STRICT] Step 1 — Project Fingerprint
- [STRICT] Detect domain, scale, risk, and tech direction from `brief.md`/repo
- [STRICT] Build `phase-sequence` tailored to domain (web, data, ML, platform)
- [GUIDELINE] Extend phases for regulated domains (health/finance/gov)

### [STRICT] Step 2 — Persona Synthesis
- [STRICT] Create per-phase personas:
  - BuilderPersona: executes the phase
  - AuditorPersona: validates independently (fresh session)
  - ChallengerPersona: proposes ≥3 improvement deltas
- [STRICT] Emit persona system instructions (2–4 lines) with core principles
- [GUIDELINE] Add domain specialists (e.g., Threat Modeler, Data Steward) if needed

### [STRICT] Step 3 — Protocol Construction
For each phase:
- [STRICT] Define Inputs with path and schema hints
- [STRICT] Define Process with [STRICT]/[GUIDELINE] directives (ordered)
- [STRICT] Define Outputs with exact paths and acceptance checks
- [STRICT] Define Success Criteria with measurable gates
- [STRICT] Provide ✅/❌ examples with pass/fail rationale
- [GUIDELINE] Link to automation hooks (scripts/actions) if available

### [STRICT] Step 4 — Validation Orchestration
- [STRICT] 3-session loop per phase:
  - Builder → Auditor → Challenger → Convergence (“PASS” required)
- [STRICT] Persist transcripts:
  - `/var/validation/<project-id>/phase-<n>/{builder.md,auditor.md,challenger.md,convergence.md}`
- [STRICT] Record convergence PASS/FAIL plus remediation commitments before advancing
- [STRICT] Record deltas and diffs before progressing
- [GUIDELINE] Gate progression via JSON schema checks

### [STRICT] Step 5 — Contracts and Schemas
- [STRICT] Emit phase I/O schemas:
  - `/var/schemas/<project-id>/phase-contracts/phase-<n>-inputs.schema.json`
  - `/var/schemas/<project-id>/phase-contracts/phase-<n>-outputs.schema.json`
- [STRICT] Validate: outputs(N) must satisfy inputs(N+1)
- [GUIDELINE] Include evidence manifest schema per phase

### [STRICT] Step 6 — Evidence Map
- [STRICT] Create `/docs/plans/<project-id>/phase-map.md` with:
  - Phase order, persona map, inputs/outputs, gates, schemas
- [GUIDELINE] Include links to compliance matrices and quality rails

---

## [STRICT] Canonical Phase Set (auto-pruned per project)
1) Phase 0 — Bootstrap
- [STRICT] Persona: AI Project Initializer
- [STRICT] Core Principle: Context mastery before motion
- [STRICT] Inputs: `brief.md`, `AGENTS.md`, and repository scan results
- [STRICT] Outputs:
  - `evidence/phase0/context-kit.md`
  - `evidence/phase0/stakeholder-map.md`
  - `evidence/phase0/tech-inventory.md`
  - `evidence/phase0/validation.md`
- [STRICT] Validation Artifacts: `var/validation/phase-0/{builder.md,auditor.md,challenger.md,convergence.md}`
- [STRICT] Success Criteria:
  - Tooling, CI/CD, security, and compliance gates enumerated with owners
  - Stakeholder matrix includes decision rights and escalation paths
- [STRICT] ✅ Example: Inventory lists all repos, pipelines, gates_config links, and pending risks
- [STRICT] ❌ Example: Missing IaC scripts, unverified secrets policy, or empty validation log

2) Phase 1 — PRD
- [STRICT] Persona: AI Product Discovery Lead
- [STRICT] Core Principle: Business truth first
- [STRICT] Outputs:
  - `evidence/phase1/prd.md`
  - `evidence/phase1/business-logic.md`
  - `evidence/phase1/user-journeys.md`
  - `evidence/phase1/acceptance-criteria.md`
  - `evidence/phase1/validation.md`
- [STRICT] Validation Artifacts: `var/validation/phase-1/{builder.md,auditor.md,challenger.md,convergence.md}`
- [STRICT] Success Criteria:
  - Acceptance criteria measurable, testable, and mapped to user journeys
  - Business logic reconciles upstream constraints and downstream dependencies
- [STRICT] ✅ Example: PRD links personas to acceptance criteria with dependency notes and mitigation plan
- [STRICT] ❌ Example: Business logic omits data contracts or conflicts with Phase 0 tech inventory

3) Phase 2 — Design & Planning
- [STRICT] Persona: AI Architecture Designer
- [STRICT] Outputs:
  - `evidence/phase2/architecture.md`
  - `evidence/phase2/api-contracts.yaml`
  - `evidence/phase2/coding-standards.md`
  - `evidence/phase2/implementation-roadmap.md`
  - `evidence/phase2/adr-catalog.md`
  - `evidence/phase2/validation.md`
- [STRICT] Validation Artifacts: `var/validation/phase-2/{builder.md,auditor.md,challenger.md,convergence.md}`
- [STRICT] Success Criteria:
  - Architecture decisions mapped to ADR IDs with risk trade-offs documented
  - Roadmap covers critical path, dependencies, and contingency buffers
- [STRICT] ✅ Example: Roadmap includes phased milestones, resource plan, and ADR cross-links
- [STRICT] ❌ Example: API contracts omit error handling or drift from acceptance criteria

4) Phase 3 — Quality Rails
- [STRICT] Persona: AI QA Specialist
- [STRICT] Outputs:
  - `evidence/phase3/security-checklist.md`
  - `evidence/phase3/performance-budgets.json`
  - `evidence/phase3/a11y-plan.md`
  - `evidence/phase3/test-plan.md`
  - `evidence/phase3/code-review-checklist.md`
  - `evidence/phase3/validation.md`
- [STRICT] Validation Artifacts: `var/validation/phase-3/{builder.md,auditor.md,challenger.md,convergence.md}`
- [STRICT] Success Criteria:
  - Security, performance, accessibility, and testing gates runnable with owners and cadence
  - Quality rails reference tooling scripts and expected telemetry thresholds
- [STRICT] ✅ Example: Performance budgets cite tooling (k6/Lighthouse) with pass thresholds and alert routing
- [STRICT] ❌ Example: Accessibility plan lacks WCAG mappings or automation instructions

5) Phase 4 — Integration
- [STRICT] Persona: AI Integration Engineer
- [STRICT] Outputs:
  - `evidence/phase4/observability-spec.md`
  - `evidence/phase4/slo-sli.md`
  - `evidence/phase4/staging-smoke-playbook.md`
  - `evidence/phase4/deployment-pipeline.md`
  - `evidence/phase4/validation.md`
- [STRICT] Validation Artifacts: `var/validation/phase-4/{builder.md,auditor.md,challenger.md,convergence.md}`
- [STRICT] Success Criteria:
  - Observability dashboards linked, SLO/SI metrics baselined, and smoke tests automated
  - Deployment pipeline documents rollback strategy with verification steps
- [STRICT] ✅ Example: Pipeline doc references IaC repos, approvals, and smoke test commands with owners
- [STRICT] ❌ Example: SLO sheet lacks alert thresholds or staging telemetry evidence

6) Phase 5 — Launch
- [STRICT] Persona: AI Deployment Specialist
- [STRICT] Outputs:
  - `evidence/phase5/deployment-runbook.md`
  - `evidence/phase5/rollback-plan.md`
  - `evidence/phase5/production-observability.md`
  - `evidence/phase5/backup-policy.md`
  - `evidence/phase5/release-notes.md`
  - `evidence/phase5/validation.md`
- [STRICT] Validation Artifacts: `var/validation/phase-5/{builder.md,auditor.md,challenger.md,convergence.md}`
- [STRICT] Success Criteria:
  - Launch gates signed off by stakeholders with rollback rehearsals complete
  - Production monitoring, backups, and communications scheduled and validated
- [STRICT] ✅ Example: Runbook lists release windows, approval checklist, and rollback verification logs
- [STRICT] ❌ Example: Backup policy missing RPO/RTO targets or restore verification evidence

7) Phase 6 — Operations
- [STRICT] Persona: AI Operations Manager
- [STRICT] Outputs:
  - `evidence/phase6/slo-monitoring.md`
  - `evidence/phase6/incident-response.md`
  - `evidence/phase6/postmortem-template.md`
  - `evidence/phase6/dependency-update-log.md`
  - `evidence/phase6/retrospective-template.md`
  - `evidence/phase6/validation.md`
- [STRICT] Validation Artifacts: `var/validation/phase-6/{builder.md,auditor.md,challenger.md,convergence.md}`
- [STRICT] Success Criteria:
  - Active SLO monitoring with alert routing and incident rehearsal cadence
  - Postmortem and dependency hygiene processes documented with owners
- [STRICT] ✅ Example: Monitoring deck links Grafana dashboards, on-call rotations, and incident drill results
- [STRICT] ❌ Example: Dependency log missing patch cadence or untracked critical CVEs

Each phase includes Builder, Auditor, Challenger, and Convergence session artifacts under `/var/validation/<project-id>/phase-<n>/` with PASS required before advancing.

---

## [STRICT] Quality Gates (Global)
- Static: lint, format, types, license headers, spellcheck, secret scan
- Dynamic: unit/integration/e2e, perf smoke, a11y axe, bundle size budgets
- Policy: OPA/Rego rulepacks (security/PII/compliance)
- ADR: `docs/adr/ADR-XXXX.md` for key decisions; link ADRs in diffs

---

## [STRICT] Invocation Contract (How this generator runs)
- [STRICT] Trigger: “Generate Rulebook for <project-id>”
- [STRICT] Inputs discovery priority:
  1) `brief.md` if present
  2) `AGENTS.md` directives
  3) Repo scan (template-packs, gates_config, workflows)
- [STRICT] Generation steps: Fingerprint → Personas → Protocols → Schemas → Evidence Map → Emit files
- [STRICT] Idempotency: Re-runs update `_generated/<project-id>` and append change log

---

## [STRICT] Success Criteria (for this generator)
- All required outputs emitted with valid frontmatter and cross-links
- Phase contracts compile; outputs(N) satisfy inputs(N+1)
- Validation session scaffolds exist for all phases
- Examples present with clear pass/fail rationale
- Evidence map complete and discoverable from one entrypoint

## [GUIDELINE] Adaptation
- Prune or extend phases per domain (data/ML/platform)
- Add domain personas (e.g., Data Privacy Officer, MLOps Lead)
- Tune gates per risk profile; raise/lower thresholds explicitly
