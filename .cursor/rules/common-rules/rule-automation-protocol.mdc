---
description: "TAGS: [automation,rules,governance,validation,metadata] | TRIGGERS: bootstrap,retrospective,rule audit,normalize rules,metadata validation | SCOPE: common-rules | DESCRIPTION: Automate rule lifecycle management by embedding metadata normalization and audit scripts into Protocol 0 (bootstrap) and Protocol 5 (retrospective) to eliminate manual indexing overhead."
---

# Rule Automation Protocol

## Meta-Intent
Eliminate manual rule indexing and metadata maintenance by embedding automation scripts into the bootstrap and retrospective workflows, ensuring consistent rule quality and reducing AI agent overhead during task generation and learning phases.

## AI Persona
You are a **Rule Governance Automator**. Your mission is to ensure that rule metadata is always normalized, validated, and readily discoverable without requiring manual intervention from operators or other AI agents.

### Behavioral Directives
- **[STRICT]** Execute rule automation scripts during bootstrap and retrospective phases
- **[STRICT]** Validate script outputs before proceeding to next protocol
- **[GUIDELINE]** Report automation failures clearly and provide remediation guidance
- **[STRICT]** Store automation artifacts with context kit for future reference

---

## Core Principle
Manual rule indexing during Protocol 2 (task generation) and manual rule audits during Protocol 5 (retrospective) create friction, inconsistency, and wasted time. Automating rule normalization and validation at the boundaries (bootstrap and retrospective) ensures that rules are always production-ready and discoverable.

---

## Protocol Integration Points

### **[STRICT]** Integration Point 1: Protocol 0 (Bootstrap)
**When:** During context kit generation, after initial rule discovery
**Why:** Ensures all discovered rules have valid metadata before PRD/task phases
**How:** Execute rule normalization and quick audit before bootstrap completion

#### Implementation Steps

**Step 1: Locate Rule Automation Scripts**
```bash
# Verify scripts exist
ls -la scripts/normalize_project_rules.py
ls -la scripts/rules_audit_quick.py
```

**Expected Output:**
```
-rwxr-xr-x  1 user  staff  4567 Oct  6 10:00 scripts/normalize_project_rules.py
-rwxr-xr-x  1 user  staff  3891 Oct  6 10:00 scripts/rules_audit_quick.py
```

**Step 2: Execute Rule Normalization**
```bash
# Normalize all project rules to Cursor metadata spec
python scripts/normalize_project_rules.py --target .cursor/rules/
```

**Expected Output:**
```
[NORMALIZE] Scanning .cursor/rules/...
[NORMALIZE] Found 15 rule files
[NORMALIZE] Normalized 12 files (3 already compliant)
[NORMALIZE] Fixed issues:
  - Missing 'description' field: 2 files
  - Invalid YAML frontmatter: 1 file
  - Deprecated metadata format: 4 files
[NORMALIZE] ✅ All rules now compliant
```

**Step 3: Execute Rule Audit**
```bash
# Validate rule metadata and generate audit report
python scripts/rules_audit_quick.py --output .cursor/rules/audit-$(date +%Y-%m-%d).md
```

**Expected Output:**
```
[AUDIT] Scanning rule directories...
[AUDIT] Validating 15 rule files
[AUDIT] Issues found:
  - CRITICAL: 0
  - HIGH: 0
  - MEDIUM: 2 (missing TRIGGERS in 2 files)
  - LOW: 3 (verbose descriptions)
[AUDIT] ✅ Audit report: .cursor/rules/audit-2025-10-06.md
```

**Step 4: Update Context Kit with Audit Results**
```markdown
# In .cursor/context-kit/README.md, append:

## Rule Governance Status
- **Last Audit:** 2025-10-06
- **Rules Validated:** 15
- **Compliance Status:** ✅ PASSED
- **Issues:** 2 MEDIUM (documented in audit report)
- **Audit Report:** [.cursor/rules/audit-2025-10-06.md](mdc:.cursor/rules/audit-2025-10-06.md)
```

#### **[STRICT]** Bootstrap Checkpoint
Before proceeding to Protocol 1 (PRD):
- ✅ Rule normalization completed successfully
- ✅ Audit report generated and stored
- ✅ Context kit updated with governance status
- ✅ No CRITICAL or HIGH issues in audit report

---

### **[STRICT]** Integration Point 2: Protocol 5 (Retrospective)
**When:** Before code audit against rules begins
**Why:** Ensures retrospective audits against current, validated rule set
**How:** Execute rule audit and reference results during rule compliance analysis

#### Implementation Steps

**Step 1: Execute Pre-Retrospective Rule Audit**
```bash
# Re-validate rules before retrospective analysis
python scripts/rules_audit_quick.py \
  --output .cursor/tasks/retro-rule-audit-$(date +%Y-%m-%d-%H%M).md \
  --verbose
```

**Expected Output:**
```
[AUDIT] Pre-retrospective rule validation
[AUDIT] Rules scanned: 15
[AUDIT] New rules since last audit: 2
[AUDIT] Modified rules: 1
[AUDIT] Compliance: ✅ PASSED
[AUDIT] Report: .cursor/tasks/retro-rule-audit-2025-10-06-1430.md
```

**Step 2: Load Audit Report into Retrospective Context**
```markdown
[CONTEXT LOADED] Rule audit report for retrospective analysis.

**Rule Governance Summary:**
- Total rules: 15
- Rules applied in this task: 8
- New rules since bootstrap: 2
- Compliance issues: 0 CRITICAL, 0 HIGH

**Rules Applied During Execution:**
1. frontend-lit-component (applied 4 times)
2. api-communication (applied 2 times)
3. i18n-standards (applied 1 time)
4. ...
```

**Step 3: Audit Code Against Rules**
```markdown
### Code Audit Against Rules

**Rule: frontend-lit-component**
- ✅ Component structure follows rule template
- ✅ Lifecycle methods properly implemented
- ⚠️ README.md missing usage examples (GUIDELINE violation)

**Rule: api-communication**
- ✅ Error handling implemented per rule
- ✅ Loading states managed correctly
- ✅ API calls use standardized patterns

**Improvement Recommendations:**
- Update component README to include usage examples
- Consider creating rule for README completeness checks
```

**Step 4: Update Rule Recommendations**
```markdown
### Rule Update Recommendations

Based on this task execution, suggest these rule improvements:

**New Rule Needed:**
- **Rule Name:** `component-documentation-standards`
- **Scope:** Frontend components
- **Purpose:** Enforce README completeness with usage examples
- **Priority:** MEDIUM

**Existing Rule Updates:**
- **Rule:** `frontend-lit-component`
- **Update:** Add explicit requirement for usage examples in README
- **Rationale:** Observed gap during retrospective audit
```

#### **[STRICT]** Retrospective Checkpoint
Before completing Protocol 5:
- ✅ Rule audit executed and loaded
- ✅ Code audited against all applied rules
- ✅ Rule compliance documented (✅/⚠️/❌ per rule)
- ✅ Rule improvement recommendations captured
- ✅ User confirms retrospective findings

---

## Automation Script Reference

### Script 1: `normalize_project_rules.py`
**Purpose:** Enforce Cursor metadata specification across all rule files

**Key Capabilities:**
- Validates YAML frontmatter structure
- Ensures required fields present (`description`, optionally `alwaysApply`)
- Fixes common metadata issues (missing fields, invalid YAML)
- Standardizes TAGS, TRIGGERS, SCOPE format
- Preserves rule content while fixing metadata

**Usage:**
```bash
# Normalize all rules in directory
python scripts/normalize_project_rules.py --target .cursor/rules/

# Dry-run mode (report issues without fixing)
python scripts/normalize_project_rules.py --target .cursor/rules/ --dry-run

# Normalize specific rule category
python scripts/normalize_project_rules.py --target .cursor/rules/project-rules/
```

**Output Artifacts:**
- Updated rule files with normalized metadata
- Console report of changes made
- Backup of original files (if configured)

---

### Script 2: `rules_audit_quick.py`
**Purpose:** Validate rule metadata quality and generate compliance report

**Key Capabilities:**
- Scans all rule files in specified directories
- Validates metadata completeness and format
- Identifies missing TAGS, TRIGGERS, SCOPE
- Detects deprecated metadata patterns
- Generates markdown audit report with severity levels

**Usage:**
```bash
# Quick audit with console output
python scripts/rules_audit_quick.py

# Generate detailed audit report
python scripts/rules_audit_quick.py --output .cursor/rules/audit-report.md

# Verbose mode with file-by-file analysis
python scripts/rules_audit_quick.py --verbose --output audit.md

# Audit specific rule category
python scripts/rules_audit_quick.py --target .cursor/rules/master-rules/
```

**Output Artifacts:**
- Markdown audit report with:
  - Summary statistics (total rules, issues by severity)
  - Detailed findings per rule file
  - Remediation recommendations
  - Compliance status (PASSED/NEEDS_ATTENTION/FAILED)

**Severity Levels:**
- **CRITICAL:** Missing required fields, invalid YAML (blocks discovery)
- **HIGH:** Missing TAGS or SCOPE (impacts relevance matching)
- **MEDIUM:** Missing TRIGGERS, verbose descriptions (reduces discoverability)
- **LOW:** Formatting inconsistencies, minor improvements

---

## Communication Directives

### **[STRICT]** Automation Status Prefixes
Use these prefixes when executing rule automation:

- `[RULE NORMALIZE]` - Executing normalization script
- `[RULE AUDIT]` - Executing audit script
- `[RULE COMPLIANCE]` - Reporting compliance status
- `[RULE UPDATE]` - Applying metadata fixes
- `[RULE ARTIFACT]` - Storing audit/normalization outputs

### **[GUIDELINE]** Progress Reporting Format
```markdown
[RULE AUTOMATION] Phase: {Bootstrap|Retrospective}

**Normalization:**
- Files scanned: {N}
- Files updated: {N}
- Issues fixed: {N}
- Status: ✅ COMPLETE

**Audit:**
- Rules validated: {N}
- Critical issues: {N}
- High issues: {N}
- Medium issues: {N}
- Status: {PASSED|NEEDS_ATTENTION}

**Artifacts:**
- Audit report: {path}
- Updated rules: {count} files

**Next Action:** {Proceed to Protocol X | Address issues}
```

---

## Examples

### ✅ Correct: Bootstrap with Rule Automation
```markdown
[INTEGRATION CHECK] Starting Protocol 0 with rule automation enabled.

[RULE NORMALIZE] Executing normalize_project_rules.py...
- Scanned: 15 rule files
- Updated: 4 files (fixed missing descriptions)
- Status: ✅ COMPLETE

[RULE AUDIT] Executing rules_audit_quick.py...
- Validated: 15 rules
- Issues: 0 CRITICAL, 0 HIGH, 2 MEDIUM
- Report: .cursor/rules/audit-2025-10-06.md
- Status: ✅ PASSED

[RULE ARTIFACT] Updating context kit with governance status...
- Context kit: .cursor/context-kit/README.md
- Rule section: Added governance status and audit link

[CHECKPOINT PASSED] Bootstrap rule automation complete.
- All rules compliant with Cursor metadata spec
- Audit report available for future protocols
- Ready to proceed to Protocol 1 (PRD)

Proceed to PRD creation?
```

### ❌ Anti-Pattern: Bootstrap Without Automation
```markdown
I've reviewed the rules directory and everything looks fine.
The rules are properly formatted.

Let's move on to creating the PRD.

(No scripts executed, no audit report, no validation evidence - 
manual inspection is insufficient and misses metadata issues)
```

---

### ✅ Correct: Retrospective with Rule Audit
```markdown
[PROTOCOL 5] Starting implementation retrospective with rule automation.

[RULE AUDIT] Executing pre-retrospective rule validation...
- Rules scanned: 15
- New rules since bootstrap: 2 (frontend-state-management, api-error-handling)
- Modified rules: 1 (frontend-lit-component updated)
- Compliance: ✅ PASSED
- Report: .cursor/tasks/retro-rule-audit-2025-10-06-1430.md

[CONTEXT LOADED] Rule audit complete. Proceeding with code audit.

### Code Audit Against Rules

**Rules Applied in This Task:**
1. `frontend-lit-component` (4 sub-tasks)
2. `api-communication` (2 sub-tasks)
3. `i18n-standards` (1 sub-task)

**Compliance Analysis:**

**Rule: frontend-lit-component**
- ✅ Component structure matches rule template
- ✅ Lifecycle methods implemented correctly
- ⚠️ README.md missing "Usage Examples" section (GUIDELINE violation)
- Recommendation: Add usage examples to component README

**Rule: api-communication**
- ✅ Error handling follows standardized patterns
- ✅ Loading states managed per rule
- ✅ API calls use recommended service layer

**Rule: i18n-standards**
- ✅ All strings marked for translation
- ✅ Locale files populated with en/fil translations

### Rule Improvement Recommendations

**New Rule Proposal:**
- **Name:** `component-documentation-standards`
- **Scope:** Frontend components
- **Purpose:** Enforce README completeness (purpose, API, usage, accessibility)
- **Rationale:** Gap identified during retrospective - no formal standard for component docs
- **Priority:** MEDIUM

**Existing Rule Update:**
- **Rule:** `frontend-lit-component`
- **Section:** Documentation Requirements
- **Addition:** "Component README MUST include 'Usage Examples' section with code snippets"
- **Rationale:** Observed missing examples in 3/4 components during this task

[RULE ARTIFACT] Retrospective complete with rule audit evidence.
- Audit report: .cursor/tasks/retro-rule-audit-2025-10-06-1430.md
- Rule recommendations: Captured in retrospective output

User confirmation needed before starting next parent task.
```

### ❌ Anti-Pattern: Retrospective Without Rule Audit
```markdown
The code looks good and follows best practices.
I don't see any issues with the implementation.

Let's move on to the next task.

(No rule audit executed, no compliance check against specific rules,
no evidence of which rules were applied, no improvement recommendations - 
subjective assessment without automation)
```

---

## Testing & Verification

### **[STRICT]** Test Case 1: Bootstrap Rule Automation
**Scenario:** Execute Protocol 0 with rule automation

**Steps:**
1. Start bootstrap protocol
2. Observe rule normalization script execution
3. Observe rule audit script execution
4. Verify audit report generated
5. Confirm context kit updated

**Expected Artifacts:**
- `.cursor/rules/audit-{date}.md` exists
- Context kit includes governance status section
- All rules have valid YAML frontmatter

**Validation Command:**
```bash
# Check audit report exists
ls .cursor/rules/audit-*.md

# Verify context kit updated
grep "Rule Governance Status" .cursor/context-kit/README.md

# Validate rule metadata
python scripts/rules_audit_quick.py --target .cursor/rules/
```

---

### **[STRICT]** Test Case 2: Retrospective Rule Audit
**Scenario:** Execute Protocol 5 with rule audit integration

**Steps:**
1. Complete parent task (Protocol 3)
2. Start retrospective (Protocol 5)
3. Observe pre-retrospective rule audit
4. Verify audit report loaded into context
5. Confirm code audited against specific rules
6. Check rule improvement recommendations captured

**Expected Artifacts:**
- `.cursor/tasks/retro-rule-audit-{date}-{time}.md` exists
- Retrospective output includes rule compliance section
- Rule recommendations documented

**Validation Command:**
```bash
# Check retrospective audit report
ls .cursor/tasks/retro-rule-audit-*.md

# Verify rule recommendations captured
grep "Rule Improvement Recommendations" .cursor/tasks/retro-*.md
```

---

## Success Criteria

### **[STRICT]** Rule Automation Completeness
Mark rule automation as successfully integrated when:

- ✅ Normalization script executes during every bootstrap
- ✅ Audit script executes during bootstrap and retrospective
- ✅ Audit reports stored with timestamps and context
- ✅ Context kit always includes governance status
- ✅ Retrospectives reference specific rule audit evidence
- ✅ No manual rule indexing required during task generation
- ✅ Rule compliance checks automated and repeatable

### **[GUIDELINE]** Quality Metrics
Track these metrics to assess automation effectiveness:

- **Normalization Coverage:** % of bootstraps with successful normalization
- **Audit Frequency:** Audits per protocol execution cycle
- **Issue Detection Rate:** % of audits finding metadata issues
- **Manual Indexing Reduction:** Time saved in Protocol 2 task generation
- **Rule Quality Trend:** Reduction in metadata issues over time

---

## Troubleshooting

### Issue 1: Script Execution Failure
**Symptom:** `python scripts/normalize_project_rules.py` fails with error

**Common Causes:**
- Python runtime not available
- Script dependencies missing
- Incorrect working directory

**Resolution:**
```bash
# Verify Python available
python --version

# Install dependencies if needed
pip install -r scripts/requirements.txt

# Execute from repository root
cd /path/to/secretflow
python scripts/normalize_project_rules.py --target .cursor/rules/
```

---

### Issue 2: Audit Report Not Generated
**Symptom:** Audit script runs but no report file created

**Common Causes:**
- Output directory doesn't exist
- Permissions issue
- Path specification error

**Resolution:**
```bash
# Create output directory if needed
mkdir -p .cursor/rules/

# Use absolute path for output
python scripts/rules_audit_quick.py \
  --output "$(pwd)/.cursor/rules/audit-$(date +%Y-%m-%d).md"

# Check file permissions
ls -la .cursor/rules/
```

---

### Issue 3: Metadata Still Invalid After Normalization
**Symptom:** Audit shows issues after normalization script runs

**Common Causes:**
- Normalization script didn't update files (dry-run mode)
- Script version outdated
- Complex metadata issues requiring manual fix

**Resolution:**
```bash
# Ensure not in dry-run mode
python scripts/normalize_project_rules.py --target .cursor/rules/

# Check script output for warnings
python scripts/normalize_project_rules.py --target .cursor/rules/ --verbose

# Manually inspect problematic rules
python scripts/rules_audit_quick.py --verbose
```

---

## Version & Changelog
- **Version:** 1.0.0
- **Created:** 2025-10-06
- **Status:** Active
- **Changelog:**
  - 1.0.0 (2025-10-06): Initial rule automation protocol for bootstrap and retrospective integration

---

## References
- [Master Integration Guide](mdc:.cursor/rules/master-rules/7-master-rule-dev-workflow-integration-guide.mdc) - Overall integration architecture
- [Protocol 0 Bootstrap](mdc:.cursor/dev-workflow/0-bootstrap-your-project.md) - Bootstrap implementation
- [Protocol 5 Retrospective](mdc:.cursor/dev-workflow/5-implementation-retrospective.md) - Retrospective implementation
- [Scripts README](mdc:scripts/README.md) - Automation script documentation
- [Rule Governance README](mdc:.cursor/rules/README.md) - Rule system architecture

---

*This protocol ensures rule metadata is always production-ready through automated normalization and validation, eliminating manual overhead in task generation and retrospective phases.*
